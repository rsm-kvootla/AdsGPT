{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qR7LozrPKL0_"
   },
   "outputs": [],
   "source": [
    "\n",
    "# List of words to search for\n",
    "search_words = [\n",
    "    \"buy\", \"purchase\", \"price\", \"order\", \"shop\", \"market\", \"checkout\", \"sell\", \"trade\", \"offer\", \"listing\", \"recommend product\",\n",
    "    \"need a service\", \"looking for service\", \"find service\", \"require service\", \"brand name\", \"store\", \"official store\",\n",
    "    \"authorized retailer\", \"nearest store\", \"find store\", \"location of store\", \"shop nearby\", \"discount\", \"deal\", \"promotion\",\n",
    "    \"coupon\", \"voucher\", \"sale\", \"clearance\", \"bargain\", \"discounted\", \"compare prices\", \"payment plan\", \"subscription\",\n",
    "    \"membership\", \"free trial\", \"financing options\", \"lease\", \"insurance\", \"loan\", \"mortgage\", \"investment\",\n",
    "    \"credit card\", \"home loan\", \"product\", \"computer repair\", \"invoice\", \"payment\", \"refund\",\n",
    "    \"warranty\", \"consultation\", \"car rental\", \"how much\", \"cost\", \"insurance quote\", \"mobile plan\", \"ticket\", \"data package\",\n",
    "    \"flight booking\", \"hotel reservation\", \"book trip\", \"subscription\", \"subscribe\", \"flight\",\n",
    "    \"gift card\", \"spend\", \"earn\", \"cashback\", \"loyalty point\", \"dollar\", \"shipping\", \"delivery\", \"in stock\", \"pre-order\", \"preorder\", \"promocode\", \"promo code\", \"promo-code\", \"book\"\n",
    "]\n",
    "\n",
    "\n",
    "# List of words to filter out\n",
    "filter_out_words = [\n",
    "    \"story\", \"fiction\", \"hypothetical\", \"roleplay\", \"role play\", \"pokemon\", \"drama\", \"seraphina\", \"natsuki\", \"kai\",\n",
    "    \"sex\", \"essay\", \"poem\", \"author\", \"compose\", \"once upon a time\", \"fanfic\", \"fan fic\", \"python\",\n",
    "    \"c++\", \"assembly language\", \"sql\", \"html\", \"monika\", \"yuri\", \"sayori\", \"gnome\", \"luna\", \"undine\", \"wisp\", \"imagine\",\n",
    "    \"backstory\", \"dragon\", \"parody\", \"chapter\", \"drippler girl\", \"storywriting\", \"gabriel\", \"teleport\",\n",
    "    \"[player]\", \"episode\", \"c program\", \"import java\", \"import pandas\", \"following code\", \"this code\", \"query select\",\n",
    "    \"tale\", \"folktale\", \"folk\", \"proofread\", \"kingdom\", \"warlord\", \"fairy\", \"wizard\", \"magic\", \"mystical\",\n",
    "    \"fable\", \"hero\", \"quest\", \"imagination\", \"creative writing\", \"sketch\", \"draw\", \"paint\", \"illustration\", \"artwork\",\n",
    "    \"fantasy\", \"realm\", \"medieval\", \"prince\", \"princess\", \"castle\", \"manga\", \"anime\", \"character design\", \"wizardry\",\n",
    "    \"novel\", \"protagonist\", \"villain\", \"plot\", \"narrative\", \"dialogue\", \"battle\", \"epic\", \"legend\", \"fairytale\", \"saga\",\n",
    "    \"fanart\", \"doodle\", \"myth\", \"trilogy\", \"dark lord\", \"warrior\", \"fantasy world\", \"land of\", \"oracle\", \"sorcerer\", \"sorcery\", \"battlefield\", \"tournament\", \"summon\",\n",
    "    \"realm\", \"3D model\", \"render\", \"coding problem\", \"debugging\", \"compile error\", \"syntax error\",\n",
    "    \"recursive function\", \"algorithm\", \"art prompt\", \"fanfiction\", \"fan art\", \"compose a song\", \"character arc\",\n",
    "    \"math problem\", \"solve for\", \"calculus\", \"algebra\", \"geometry\", \"trigonometry\", \"integral\", \"derivative\", \"equation\",\n",
    "    \"formula\", \"proof\", \"theorem\", \"variable\", \"find x\", \"factorize\", \"matrix\", \"determinant\", \"vector\",\n",
    "    \"probability\", \"statistics\", \"mean\", \"median\", \"mode\", \"standard deviation\", \"variance\", \"binomial\",\n",
    "    \"hypothesis test\", \"z-score\", \"p-value\", \"assignment\", \"homework\", \"problem set\",\n",
    "    \"exam\", \"quiz\", \"calculate\", \"logarithm\",\n",
    "    \"exponential\", \"partial derivative\", \"differential equation\", \"complex numbers\",\n",
    "    \"number theory\", \"graph theory\", \"discrete math\", \"combinatorics\", \"geometry proof\",\n",
    "    \"coordinate plane\", \"function\", \"integer\", \"rational number\",\n",
    "    \"real number\", \"modulus\", \"quadratic\", \"linear equation\", \"inequality\",\"radians\", \"degrees\", \"cosine\", \"sine\", \"cotangent\", \"secant\",\n",
    "    \"cosecant\", \"assignment help\", \"academic help\", \"math tutor\", \"geometry help\", \"solve this equation\",\n",
    "    \"homework help\", \"show your work\", \"assignment question\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XSfQb2bsKL1L"
   },
   "source": [
    "**Ultrachat**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x7Qm6MTXKL1O",
    "outputId": "b4da2cf7-f511-4388-ae78-f5c22a50ffe4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              prompt  \\\n",
      "0  How does the author propose to fix the problem...   \n",
      "1  Rice tolerance to suboptimal low temperatures ...   \n",
      "2  Write a free verse poem about the power of the...   \n",
      "3  Compose a speech about the need for more affor...   \n",
      "4  Write a historical fiction story that is set d...   \n",
      "\n",
      "                                           prompt_id  \\\n",
      "0  9fb649a870769f4881c647d20d178656f67fc881b2dc0b...   \n",
      "1  26afb4f9bffc82fbbfdcaa8f0eec0833780e411799dcee...   \n",
      "2  3ab0d0c24777248cbc4aa33971d34e8de9393db1ea0cc1...   \n",
      "3  5dac3c072ba477af9ed0c71a31a806f307d7ea839a7977...   \n",
      "4  b750ea229635aa6683e0018abd17f92804376c1b0c474d...   \n",
      "\n",
      "                                            messages  \n",
      "0  [{'content': 'How does the author propose to f...  \n",
      "1  [{'content': 'Rice tolerance to suboptimal low...  \n",
      "2  [{'content': 'Write a free verse poem about th...  \n",
      "3  [{'content': 'Compose a speech about the need ...  \n",
      "4  [{'content': 'Write a historical fiction story...  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Ultrachat\n",
    "ultrachat = pd.read_parquet('test_sft-00000-of-00001-f7dfac4afe5b93f4.parquet')\n",
    "print(ultrachat.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cJ_mxQClKL1R",
    "outputId": "fd574e53-bd11-4610-aa3d-f44c2cbcc0b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "914      Write a Rust program that prompts the user to ...\n",
      "12182    From the kitchen of One Perfect Bite...I made ...\n",
      "10694    Please provide step-by-step instructions on ho...\n",
      "6174     One of my favorite things to do is gather peop...\n",
      "10906    How can exercise help in practicing mindfulnes...\n",
      "Name: prompt, dtype: object\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "# Assuming df is your DataFrame and it has a column 'A'\n",
    "# Sample 500 random rows from the DataFrame\n",
    "sample_df = ultrachat['prompt'].sample(n=500)\n",
    "\n",
    "print(sample_df.head())\n",
    "print(len(sample_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j0XJELNnKL1S",
    "outputId": "dfdac7c5-0464-499e-ddda-dd803f6edce8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of relevant rows: 0\n",
      "Percentage of relevant rows: 0.00%\n",
      "Number of rows containing search words: 0, with a relevancy percentage of 0.00%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Filter out rows that contain any of the filter_out_words\n",
    "filtered_sample_df = sample_df[~sample_df.str.contains('|'.join(filter_out_words), case=False, na=False)]\n",
    "\n",
    "# Count the rows that contain any of the search_words\n",
    "count_relevant = filtered_sample_df.str.contains('|'.join(search_words), case=False, na=False).sum()\n",
    "\n",
    "# Calculate the percentage of relevant rows out of a total of 500 rows\n",
    "percent_relevant = count_relevant / 500\n",
    "\n",
    "# Output results\n",
    "print(f\"Count of relevant rows: {count_relevant}\")\n",
    "print(f\"Percentage of relevant rows: {percent_relevant * 100:.2f}%\")\n",
    "\n",
    "print(f\"Number of rows containing search words: {count_relevant}, with a relevancy percentage of {percent_relevant:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ssQyQNEVKL1U",
    "outputId": "3137ecbe-3103-4499-ee08-9ecca396b4bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: prompt, dtype: object)\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(filtered_sample_df.head())\n",
    "print(len(filtered_sample_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rxN7gecHKL1V",
    "outputId": "a56545b8-bce2-4fa2-de09-30f5e7589594"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "221\n",
      "12182    From the kitchen of One Perfect Bite...I made ...\n",
      "10694    Please provide step-by-step instructions on ho...\n",
      "5541     Read the passage below and answer the question...\n",
      "14734    Poem: The Cycle, by Cheron Turnley | POETRY FE...\n",
      "7591     Recommend a list of podcasts that are engaging...\n",
      "                               ...                        \n",
      "4299     Given the text: Customized prints are a great ...\n",
      "6897     “Alan said that I read too much,” said Karen M...\n",
      "19668    Create a 60-minute webinar presentation that d...\n",
      "1110     Here is a piece of text: FIFA 12: PC demo – In...\n",
      "3985     Please create a detailed step-by-step guide th...\n",
      "Name: prompt, Length: 221, dtype: object\n"
     ]
    }
   ],
   "source": [
    "count_relevant1 = sample_df.str.contains('|'.join(search_words), case=False, na=False).sum()\n",
    "print(count_relevant1)\n",
    "relevant_rows = sample_df[sample_df.str.contains('|'.join(search_words), case=False, na=False)]\n",
    "print(relevant_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ino8lQarKL1X"
   },
   "source": [
    "**Dialog Studio**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7ZFyENwqKL1Y",
    "outputId": "5c5642a2-0a76-46ee-d523-91c1a5c67d82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      user_utterance\n",
      "0                    Hello, I want to book a flight.\n",
      "1                     Yes that's where I want to go.\n",
      "2                       I want to leave from Dallas.\n",
      "3                    I want to leave by next Friday.\n",
      "4  Wait please don't do that, I was only curious....\n",
      "97638\n",
      "                                      user_utterance\n",
      "0                    Hello, I want to book a flight.\n",
      "1                     Yes that's where I want to go.\n",
      "2                       I want to leave from Dallas.\n",
      "3                    I want to leave by next Friday.\n",
      "4  Wait please don't do that, I was only curious....\n",
      "69616\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# Directory containing the folders with JSON files\n",
    "directory = 'AdsGPT/DSTaskOriented'\n",
    "\n",
    "# List to store the data from all JSON files\n",
    "all_data = []\n",
    "\n",
    "# Walk through the directory\n",
    "for root, dirs, files in os.walk(directory):\n",
    "    for file in files:\n",
    "        if file.endswith('.json'):\n",
    "            file_path = os.path.join(root, file)\n",
    "            with open(file_path, 'r') as f:\n",
    "                data = json.load(f)\n",
    "                all_data.append(data)\n",
    "\n",
    "# Extract user utterances from each file and combine into one DataFrame\n",
    "utterances = []\n",
    "\n",
    "for data in all_data:\n",
    "    for key, value in data.items():\n",
    "        if 'log' in value:\n",
    "            for entry in value['log']:\n",
    "                if 'user utterance' in entry:\n",
    "                    utterances.append(entry['user utterance'])\n",
    "\n",
    "# Create a DataFrame from the extracted utterances\n",
    "utterances_df = pd.DataFrame(utterances, columns=['user_utterance'])\n",
    "\n",
    "print(utterances_df.head())\n",
    "print(len(utterances_df))\n",
    "\n",
    "# Remove duplicates\n",
    "utterances_df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Remove entries with less than 3 words\n",
    "utterances_df = utterances_df[utterances_df['user_utterance'].str.split().str.len() >= 4]\n",
    "\n",
    "# Remove entries that are more than 60% numbers\n",
    "utterances_df = utterances_df[utterances_df['user_utterance'].apply(lambda x: sum(c.isdigit() for c in x) / len(x) <= 0.6)]\n",
    "\n",
    "print(utterances_df.head())\n",
    "print(len(utterances_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VItRliAiKL1a"
   },
   "outputs": [],
   "source": [
    "utterances_df.to_csv('AdsGPT/DSTaskOriented/utterances.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9NYcrNVOKL1b",
    "outputId": "5b058b61-9dd7-4b8b-d223-3810adacc5c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of relevant rows: 5\n",
      "Percentage of relevant rows: 0.01%\n"
     ]
    }
   ],
   "source": [
    "# Filter out rows that contain any of the filter_out_words\n",
    "filtered_utterances_df = utterances_df[~utterances_df['user_utterance'].str.contains('|'.join(filter_out_words), case=False, na=False)]\n",
    "\n",
    "# Count the rows that contain any of the search_words\n",
    "count_relevant_utterances = filtered_utterances_df['user_utterance'].str.contains('|'.join(search_words), case=False, na=False).sum()\n",
    "\n",
    "# Calculate the percentage of relevant rows out of the total number of rows\n",
    "percent_relevant_utterances = count_relevant_utterances / len(utterances_df)\n",
    "\n",
    "# Output results\n",
    "print(f\"Count of relevant rows: {count_relevant_utterances}\")\n",
    "print(f\"Percentage of relevant rows: {percent_relevant_utterances * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "neoxMGKSKL1c",
    "outputId": "c684a3ef-6c41-4a48-d7af-b47ae260a6f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        user_utterance\n",
      "488    Ok good to know\n",
      "1157   no dont book it\n",
      "2425     Just 2 of us.\n",
      "4528  NO I'm good now.\n",
      "4632     I think so to\n",
      "73\n"
     ]
    }
   ],
   "source": [
    "print(filtered_utterances_df.head())\n",
    "print(len(filtered_utterances_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q2fpGX85KL1c",
    "outputId": "a3f6c45d-2f7e-4e7b-ea94-44d85e73614e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16471\n",
      "                                          user_utterance\n",
      "0                        Hello, I want to book a flight.\n",
      "4      Wait please don't do that, I was only curious....\n",
      "5          I need some help with some information please\n",
      "6                       how do I get a flight to Greece?\n",
      "7      I'm not really ready to book. I was just curio...\n",
      "...                                                  ...\n",
      "97611                           Chicken and beef please.\n",
      "97618  Hey. I'm thinking of seeing What Men Want toni...\n",
      "97628  Hello. Can you help me purchase a couple of mo...\n",
      "97629  I'd like to see Captain Marvel at the NCG Cine...\n",
      "97631  Ok. Can I get the tickets for just the regular...\n",
      "\n",
      "[16471 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "count_relevant_ds = utterances_df['user_utterance'].str.contains('|'.join(search_words), case=False, na=False).sum()\n",
    "print(count_relevant_ds)\n",
    "relevant_rows_ds = utterances_df[utterances_df['user_utterance'].str.contains('|'.join(search_words), case=False, na=False)]\n",
    "print(relevant_rows_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WZDusZwuKL1d"
   },
   "source": [
    "**ShareGPT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_cKvxFREKL1e",
    "outputId": "917491ac-6bf2-458d-ad44-4ab070d70b59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             human_values\n",
      "219631  Hello ChatGPT. You are about to immerse yourse...\n",
      "72999   Original Question:\\t9\\t:\\tWhich of the followi...\n",
      "541433  Write an essay of approximately 250 words that...\n",
      "606293  Based on our previous conversation, can you he...\n",
      "14932   2 / 2 \\n write the code from This part: write ...\n",
      "...                                                   ...\n",
      "29972   I have dotMemory but I haven't used it yet. Do...\n",
      "343946  some product speedometer use gps but don not u...\n",
      "337190  Based on our previous conversation, can you he...\n",
      "14066   Create an mobile first website that helps peop...\n",
      "503775  Given a system in which:\\n• Address width in t...\n",
      "\n",
      "[95 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# Path to the folder containing the JSON files\n",
    "folder_path = 'AdsGPT/ShareGPT'\n",
    "\n",
    "# Function to extract values where \"from\" is \"human\"\n",
    "def extract_human_values(data):\n",
    "    values = []\n",
    "    if isinstance(data, dict):\n",
    "        for key, value in data.items():\n",
    "            if key == \"from\" and value == \"human\":\n",
    "                values.append(data.get(\"value\", \"\"))\n",
    "            elif isinstance(value, (dict, list)):\n",
    "                values.extend(extract_human_values(value))\n",
    "    elif isinstance(data, list):\n",
    "        for item in data:\n",
    "            values.extend(extract_human_values(item))\n",
    "    return values\n",
    "\n",
    "# Read all JSON files in the folder and extract values\n",
    "human_values = []\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.json'):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            data = json.load(file)\n",
    "            human_values.extend(extract_human_values(data))\n",
    "\n",
    "# Save the extracted values to a CSV file\n",
    "output_df = pd.DataFrame({'human_values': human_values})\n",
    "output_df.to_csv('human_values.csv', index=False)\n",
    "\n",
    "# Load the data from the output file\n",
    "output_df = pd.read_csv('human_values.csv')\n",
    "\n",
    "# Randomly sample lines if the filtered DataFrame has more than 500 rows\n",
    "if len(output_df) > 500:\n",
    "    sampledsgpt_df = output_df.sample(n=500)\n",
    "\n",
    "\n",
    "# Combine keywords into patterns for vectorized search\n",
    "commercial_pattern = '(?i)' + '|'.join(search_words)\n",
    "\n",
    "# Filter rows that contain any valid keywords\n",
    "valid_mask = sampledsgpt_df['human_values'].str.contains(commercial_pattern, regex=True)\n",
    "\n",
    "# Apply the filter\n",
    "filtered_df = sampledsgpt_df[valid_mask]\n",
    "\n",
    "# Display filtered DataFrame\n",
    "print(filtered_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B2eog6ztKL1f",
    "outputId": "a922aec8-bb41-4263-c784-f569478d694c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95\n"
     ]
    }
   ],
   "source": [
    "print(len(filtered_df))\n",
    "\n",
    "# Optionally save to a new CSV file\n",
    "filtered_df.to_csv('filtered_human_values.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
