{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jYKBrgQKDCd-",
    "outputId": "2ae79f55-933b-4ff9-9cd2-5f5bdbb57a33"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import glob\n",
    "\n",
    "# Load all conversations\n",
    "cleaned_dfs = []\n",
    "seen_conversations = set()\n",
    "\n",
    "\n",
    "# Combined list of phrases indicating commercial intent\n",
    "commercial_intent_phrases = [\n",
    "    \"buy\", \"purchase\", \"order\", \"checkout\", \"sell\", \"trade\", \"offer\", \"listing\", \"price\",\n",
    "    \"show me\", \"looking for\", \"searching for\", \"recommend product\", \"need a service\",\n",
    "    \"looking for service\", \"find service\", \"require service\", \"brand name\", \"store\",\n",
    "    \"official store\", \"authorized retailer\", \"nearest store\", \"find store\", \"location of store\",\n",
    "    \"shop nearby\", \"issue\", \"problem\", \"solution\"\n",
    "]\n",
    "\n",
    "#  Function to Filter conversations based on commercial intent\n",
    "def has_commercial_intent(conversation):\n",
    "    for phrase in commercial_intent_phrases:\n",
    "        if phrase in conversation.lower():\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "#Load files and filter by language and country and commercial intent\n",
    "for data_file in glob.glob('Data/*'):\n",
    "    df = pd.read_parquet(data_file)\n",
    "    df_convo = df[['conversation','country']]\n",
    "    df_convo = df_convo[df_convo['conversation'].apply(lambda x: x[0]['language'] == 'English')]\n",
    "    df_convo = df_convo[df_convo['country']=='United States']\n",
    "    df_convo = df_convo[df_convo['conversation'].apply(lambda x: has_commercial_intent(x[0].get('content', '')))]\n",
    "\n",
    "\n",
    "#Drop duplicates\n",
    "    # Function to extract the first 10 words of a conversation after \"content:\"\n",
    "    def get_first_10_words(conversation):\n",
    "        content = conversation[0].get('content', '')\n",
    "        # Extract the actual conversation starting after 'content:'\n",
    "        start_index = content.find('content:')\n",
    "        if start_index != -1:\n",
    "            content = content[start_index + len('content:'):].strip()\n",
    "        first_10_words = ' '.join(content.split()[:10])\n",
    "        return first_10_words\n",
    "\n",
    "    # Filter out conversations where the first 10 words are duplicates\n",
    "    def filter_duplicate_conversations(conversation):\n",
    "        first_10_words = get_first_10_words(conversation)\n",
    "        if first_10_words in seen_conversations:\n",
    "            return False\n",
    "        seen_conversations.add(first_10_words)\n",
    "        return True\n",
    "\n",
    "    # Apply the function to filter duplicate conversations\n",
    "    df_convo = df_convo[df_convo['conversation'].apply(filter_duplicate_conversations)]\n",
    "\n",
    "    # Drop exact duplicate conversations (if any remain)\n",
    "    df_convo = df_convo.drop_duplicates(subset=['conversation'])\n",
    "\n",
    "#only return the part of the conversation after content':' before ', 'country\n",
    "    df_convo['conversation'] = df_convo['conversation'].apply(lambda x: x[0].get('content', ''))\n",
    "\n",
    "    #Use new variable to store the clean data\n",
    "    cleaned_df = df_convo['conversation']\n",
    "    cleaned_dfs.append(cleaned_df)\n",
    "\n",
    "    # List of words to filter out\n",
    "    filter_words = [\n",
    "        \"story\", \"fiction\", \"hypothetical\", \"roleplay\", \"role play\", \"pokemon\", \"drama\", \"game\",\n",
    "        \"seraphina\", \"natsuki\", \"kai\", \"sex\", \"personal account\", \"essay\", \"poem\", \"author\",\n",
    "        \"compose\", \"once upon a time\", \"fanfic\", \"fan fic\", \"python\", \"c++\", \"assembly language\",\n",
    "        \"sql\", \"html\", \"monika\", \"yuri\", \"sayori\", \"gnome\", \"luna\", \"undine\", \"wisp\", \"imagine\",\n",
    "        \"backstory\", \"scenes\", \"dragon\", \"parody\", \"scene\", \"chapter\", \"drippler girl\",\n",
    "        \"storywriting\", \"gabriel\", \"teleport\", \"[player]\", \"episode\", \"c program\", \"imoprt java\",\n",
    "        \"import pandas\", \"following code\", \"this code\", \"query select\", \"write a\", \"tale\",\n",
    "        \"folktale\", \"folk\", \"proofread\", \"kingdom\", \"warlord\"\n",
    "    ]\n",
    "\n",
    "    # Function to check if a conversation contains any of the filter words\n",
    "    def contains_filter_words(conversation):\n",
    "        for word in filter_words:\n",
    "            if re.search(r'\\b' + re.escape(word) + r'\\b', conversation, re.IGNORECASE):\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    # Apply the filter to remove conversations containing any of the filter words\n",
    "    cleaned_dfs = [df[~df.apply(contains_filter_words)] for df in cleaned_dfs]\n",
    "\n",
    "english_convo = pd.concat(cleaned_dfs)\n",
    "print(english_convo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "udPMgZ3-DCeA"
   },
   "outputs": [],
   "source": [
    "#Save the ouput to a csv file\n",
    "english_convo.to_csv('CleanWildChat.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
